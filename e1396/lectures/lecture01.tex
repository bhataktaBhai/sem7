\chapter*{The course}
\lecture{2025-08-06}{}

\textbf{Instructor:} Shalabh Bhatnagar
\\[1em]
\textbf{Textbook:} Stochastic Approximation: A Dynamical Systems Viewpoint
by Vivek~S.~Borkar. (2022, Hindustan Book Agency)
\\[1em]
\textbf{Evaluation:}
\begin{description}
    \item[(40\%)] Two midterms
    \item[(25\%)] Final exam
    \item[(35\%)] Project
\end{description}

H.~Robbins and S.~Monro published a landmark paper in the Annals of
Mathematical Statistic in 1951.
The subject of the paper was the following.
Suppose there is a function $f\colon \R \to \R$ and iid noises
$M_1, M_2, \dots$ with zero mean.
We are to find a $\theta^*$ such that $f(\theta^*) = 0$.

They proposed what is now known as the Robbins-Monro algorithm.
Set \begin{align*}
    \theta_{n+1} &= \theta_n + a_n (f(\theta_n) + M_{n+1})
\end{align*}
$a_n$ is called the \emph{step size} or the \emph{learning rate}.
They showed that $\theta_n \to \theta^*$ with $f(\theta^*) = 0$.

Assume that the domain is a bounded box $[0, 1]^d$
One could take many samples at each mesh point in a dense mesh, and hope
that the law of large numbers allows you to sketch out $f$.
This is infeasible in practice.
The method of stochastic approximation \emph{does not yield} much
information about $f$, other than that it has a root at the limit
$\theta^*$.

\begin{examples}
    \item To find the fixed point of a given function $h$,
        set $f = h - \operatorname{id}$.
    \item Suppose $h\colon \R^d \to \R$ and we wish to find a local minimum.
        Set $f$ to be $-\nabla h$, where of course the gradients we compute
        will be noisy.
        There are known simple techniques to obtain estimates of gradients
        that at least have zero mean at minima.
\end{examples}

\section*{Roadmap}
\begin{itemize}
    \item Introduce stochastic approximation (chapter 1)
    \item Background in probability, analysis and ODEs
    \item Asymptoptic analysis of stochastic approximation, assuming
        stability of the iterates (chapter 2)
    \item Sufficient conditions for stability (chapter 3)
    \item Lock-in probability and sample complexity of stochastic
        approximation (chapter 4)
    \item Multi-timescale stochastic approximation
    \item If time permits, stochastic approximation with Markov noise
    \item Stochastic approximation with set-valued maps
\end{itemize}
Stability in this context means that $\sup_n \norm{\theta_n} < \infty$
almost surely.

\chapter{First chapter?}
The strong law of large number states that the empirical mean of iid random
variables with finite mean converges to the mean almost surely.
Let $S_n = \frac1n \sum_{i=1}^n X_i$.
Writing \begin{align*}
    S_{n+1} &= \frac n{n+1} S_n + \frac1{n+1} X_{n+1} \\
        &= \ab(1 - \frac1{n+1}) S_n + \frac1{n+1} X_{n+1} \\
        &= S_n + \frac1{n+1} (X_{n+1} - S_n) \\
        &= S_n + a_n (h(S_n) + X_{n+1})
\end{align*}
where $a_n = \frac1{n+1}$ and $h = -\operatorname{id}$.
This is now a stochastic approximation scheme if one assumes $\E[X_1] = 0$.

The corresponding ODE is \[
    \dot{s}(t) = -s(t),
\] which has an equilibrium at $s(t) = 0$.

Suppose instead that $a_n = \frac1{(n+1)^{2/3}}$.
We would still recover a strong law-like statement even though the mean is
not uniformly weighted.
